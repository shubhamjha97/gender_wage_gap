val df=spark.read.format("csv").option("header", "true").option("inferSchema", "true").load("/user/nc2263/projectinput/wagegap.csv")
df.printSchema()
df.groupBy("LOCATION").avg("Value").show(false)
df.show()
df.groupBy("LOCATION").max("Value").show(false)
df.groupBy("TIME").max("Value").show(false)
df.select("SUBJECT").distinct.show(false);
df.select("LOCATION").distinct.show(false);
df.createOrReplaceTempView("my_table");
spark.sql("""select * from my_table""");
val df2=spark.read.format("csv").option("header", "true").option("inferSchema", "true").load("/user/nc2263/projectinput/GDP.csv")
df2.select("TIME").distinct.show(false)
df.createOrReplaceTempView("my_table2");
spark.sql("""select MAX(Value) FROM my_table2""").show(false)
spark.sql("""select LOCATION, MAX(Value) as max FROM my_table2 GROUP BY LOCATION ORDER BY max asc """).show(false)
spark.sql("""select LOCATION, MAX(Value) as max FROM my_table2 GROUP BY LOCATION ORDER BY max desc """).show(false)
spark.sql("""select min(Value) as min FROM my_table2""").show(false)
spark.sql("""select AVG(Value) as max FROM my_table2 GROUP BY LOCATION ORDER BY max desc """).show(false)
val avg=df2.select(mean(df2("Value"))).show()
val higher_than_avg=df2.filter(df2("Value") >= 36596.98).show(false)
val higher_than_avg=df2.filter(df2("Value") <= 36596.98).show(false)